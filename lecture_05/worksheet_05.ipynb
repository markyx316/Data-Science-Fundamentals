{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Worksheet 05\n",
    "\n",
    "Name: Youxuan Ma\n",
    "\n",
    "UID: U23330522\n",
    "\n",
    "### Topics\n",
    "\n",
    "- Cost Functions\n",
    "- Kmeans\n",
    "\n",
    "### Cost Function\n",
    "\n",
    "Solving Data Science problems often starts by defining a metric with which to evaluate solutions were you able to find some. This metric is called a cost function. Data Science then backtracks and tries to find a process / algorithm to find solutions that can optimize for that cost function.\n",
    "\n",
    "For example suppose you are asked to cluster three points A, B, C into two non-empty clusters. If someone gave you the solution `{A, B}, {C}`, how would you evaluate that this is a good solution?\n",
    "\n",
    "Notice that because the clusters need to be non-empty and all points must be assigned to a cluster, it must be that two of the three points will be together in one cluster and the third will be alone in the other cluster.\n",
    "\n",
    "In the above solution, if A and B are closer than A and C, and B and C, then this is a good solution. The smaller the distance between the two points in the same cluster (here A and B), the better the solution. So we can define our cost function to be that distance (between A and B here)!\n",
    "\n",
    "The algorithm / process would involve clustering together the two closest points and put the third in its own cluster. This process optimizes for that cost function because no other pair of points could have a lower distance (although it could equal it)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### K means\n",
    "\n",
    "a) (1-dimensional clustering) Walk through Lloyd's algorithm step by step on the following dataset:\n",
    "\n",
    "`[0, .5, 1.5, 2, 6, 6.5, 7]` (note: each of these are 1-dimensional data points)\n",
    "\n",
    "Given the initial centroids:\n",
    "\n",
    "`[0, 2]`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dataset:\n",
    "$[0, 0.5, 1.5, 2, 6, 6.5, 7]$\n",
    "\n",
    "### Initial Centroids:\n",
    "$[c_1 = 0, c_2 = 2]$\n",
    "\n",
    "#### Step 1: Assignment Step\n",
    "\n",
    "- For $c_1 = 0$, the closest points are $[0, 0.5]$.\n",
    "- For $c_2 = 2$, the closest points are $[1.5, 2, 6, 6.5, 7]$.\n",
    "\n",
    "So, the clusters after the assignment step are:\n",
    "- Cluster 1: $[0, 0.5]$\n",
    "- Cluster 2: $[1.5, 2, 6, 6.5, 7]$\n",
    "\n",
    "#### Step 2: Update Step\n",
    "\n",
    "- New centroid for Cluster 1, $c_1$: $ \\frac{0 + 0.5}{2} = 0.25 $\n",
    "- New centroid for Cluster 2, $c_2$: $ \\frac{1.5 + 2 + 6 + 6.5 + 7}{5} = 4.6 $\n",
    "\n",
    "So, the updated centroids are:\n",
    "- $c_1 = 0.25$\n",
    "- $c_2 = 4.6$\n",
    "\n",
    "#### Step 3: Repeat Assignment\n",
    "\n",
    "- For $c_1 = 0.25$, the closest points are now $[0, 0.5, 1.5, 2]$.\n",
    "- For $c_2 = 4.6$, the closest points are now $[6, 6.5, 7]$.\n",
    "\n",
    "Clusters after the reassignment:\n",
    "- Cluster 1: $[0, 0.5, 1.5, 2]$\n",
    "- Cluster 2: $[6, 6.5, 7]$\n",
    "\n",
    "#### Step 4: Repeat Update\n",
    "\n",
    "- New centroid for Cluster 1, $c_1$: $ \\frac{0 + 0.5 + 1.5 + 2}{4} = 1 $\n",
    "- New centroid for Cluster 2, $c_2$: $ \\frac{6 + 6.5 + 7}{3} = 6.5 $\n",
    "\n",
    "Updated centroids are:\n",
    "- $c_1 = 1$\n",
    "- $c_2 = 6.5$\n",
    "\n",
    "#### Step 5: Check for Convergence\n",
    "Repeat the assignment and update steps until the centroids do not change anymore, or the change is below a certain threshold, indicating that the algorithm has converged.\n",
    "\n",
    "Since the centroids in Step 2 still differ from the ones in Step 4 by a lot, we proceed with repeating the assignment and update steps.\n",
    "\n",
    "#### Step 6: Repeat Assignment\n",
    "\n",
    "- For $c_1 = 1$, the closest points are now $[0, 0.5, 1.5, 2]$.\n",
    "- For $c_2 = 6.5$, the closest points are now $[6, 6.5, 7]$.\n",
    "\n",
    "Clusters after the reassignment:\n",
    "- Cluster 1: $[0, 0.5, 1.5, 2]$\n",
    "- Cluster 2: $[6, 6.5, 7]$\n",
    "\n",
    "#### Step 7: Repeat Update\n",
    "\n",
    "- New centroid for Cluster 1, $c_1$: $ \\frac{0 + 0.5 + 1.5 + 2}{4} = 1 $\n",
    "- New centroid for Cluster 2, $c_2$: $ \\frac{6 + 6.5 + 7}{3} = 6.5 $\n",
    "\n",
    "Updated centroids are:\n",
    "- $c_1 = 1$\n",
    "- $c_2 = 6.5$\n",
    "\n",
    "#### Step 8: Check for Convergence\n",
    "Now, we have that the newly updated centroids in Step 7 are the same as the ones in Step 4, indicating that the algorithm has converged.\n",
    "\n",
    "Therefore, we get the final result of the clustering of the given dataset:\n",
    "\n",
    "- Cluster 1: $[0, 0.5, 1.5, 2]$\n",
    "- Cluster 2: $[6, 6.5, 7]$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "b) Describe in plain english what the cost function for k means is."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The cost function for K-means evaluates how compact the clusters are by measuring how close the points within each cluster are to their respective centroids. The aim is to achieve as low a value as possible for this cost function, indicating that the algorithm has found a good grouping of the data points.\n",
    "\n",
    "In other words, the cost function measures how well the K-means algorithm has performed in grouping similar data points into clusters. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "c) For the same number of clusters K, why could there be very different solutions to the K means algorithm on a given dataset?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is often due to the Random Initialization:\n",
    "\n",
    "K-means typically starts by randomly selecting K points from the dataset as the initial centroids. Since this selection is random, different runs of the algorithm can start with different initial centroids, thus leading to different clustering outcomes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "d) Does Lloyd's Algorithm always converge? Why / why not?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Yes, Lloyd's Algorithm always converges. The reasons are:\n",
    "1. Finite Dataset:\n",
    "\n",
    "- Given a finite dataset, there are a limited number of ways to partition the data points into K clusters. Each iteration of the algorithm refines the cluster assignments based on the current centroids, moving towards a more optimal partitioning. Since the number of possible partitions is finite, the algorithm cannot continue to change the cluster assignments indefinitely. \n",
    "\n",
    "2. Cost Function Decrease:\n",
    "\n",
    "- The objective of K-means is to minimize the cost function. Each iteration of Lloyd's Algorithm (reassigning points to the nearest centroid and then updating centroids to the mean of the points in each cluster) is guaranteed to not increase the cost function. In most cases, it decreases the cost function unless the algorithm has already reached an optimal or locally optimal configuration where further iterations do not change the cluster assignments.\n",
    "\n",
    "However, while Lloyd's Algorithm is guaranteed to converge, it may converge to a local minimum of the cost function rather than the global minimum. \n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "e) Follow along in class the implementation of Kmeans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from PIL import Image as im\n",
    "import matplotlib.pyplot as plt\n",
    "import sklearn.datasets as datasets\n",
    "\n",
    "centers = [[0, 0], [2, 2], [-3, 2], [2, -4]]\n",
    "X, _ = datasets.make_blobs(n_samples=300, centers=centers, cluster_std=1, random_state=0)\n",
    "\n",
    "class KMeans():\n",
    "\n",
    "    def __init__(self, data, k):\n",
    "        self.data = data\n",
    "        self.k = k\n",
    "        self.assignment = [-1 for _ in range(len(data))]\n",
    "        self.snaps = []\n",
    "    \n",
    "    def snap(self, centers):\n",
    "        TEMPFILE = \"temp.png\"\n",
    "\n",
    "        fig, ax = plt.subplots()\n",
    "        ax.scatter(X[:, 0], X[:, 1], c=self.assignment)\n",
    "        ax.scatter(centers[:,0], centers[:, 1], c='r')\n",
    "        fig.savefig(TEMPFILE)\n",
    "        plt.close()\n",
    "        self.snaps.append(im.fromarray(np.asarray(im.open(TEMPFILE))))\n",
    "\n",
    "    def unassign_all(self):\n",
    "        self.assignment = [-1 for _ in range(len(self.data))]\n",
    "        \n",
    "    def initialize(self):\n",
    "        return self.data[np.random.choice(len(self.data), self.k, replace=False)]\n",
    "    \n",
    "    def assign(self, centers):\n",
    "        for i in range(len(self.data)):\n",
    "            temp_dist = float('inf')\n",
    "            self.assignment[i] = -1\n",
    "            for j in range(len(centers)):\n",
    "                new_dist = self.dist(self.data[i], centers[j])\n",
    "                if new_dist < temp_dist:\n",
    "                    temp_dist = new_dist\n",
    "                    self.assignment[i] = j\n",
    "                    \n",
    "    def calculate_new_centers(self):\n",
    "        centers = []\n",
    "        for j in range(self.k):\n",
    "            cluster_j = self.data[\n",
    "                np.array([i for i in range(len(self.data)) if self.assignment[i] == j])\n",
    "            ]\n",
    "            centers.append(np.mean(cluster_j, axis=0))\n",
    "        return np.array(centers)\n",
    "                \n",
    "    def dist(self, x, y):\n",
    "        return sum((x - y)**2)**.5\n",
    "    \n",
    "    \n",
    "    def are_centers_diff(self, centers, new_centers):\n",
    "        for i in range(len(centers)):\n",
    "            if centers[i] not in new_centers:\n",
    "                return True\n",
    "        return False\n",
    "    \n",
    "    def lloyds(self):\n",
    "        centers = self.initialize()\n",
    "        self.assign(centers)\n",
    "        self.snap(centers)\n",
    "        new_centers = self.calculate_new_centers()\n",
    "        while self.are_centers_diff(centers, new_centers):\n",
    "            centers = new_centers\n",
    "            self.snap(centers)\n",
    "            self.unassign_all()\n",
    "            self.assign(centers)\n",
    "            new_centers = self.calculate_new_centers()\n",
    "        return\n",
    "    \n",
    "    def is_unassigned(self, i):\n",
    "        return self.assignment[i] == -1\n",
    "            \n",
    "\n",
    "kmeans = KMeans(X, 6)\n",
    "kmeans.lloyds()\n",
    "images = kmeans.snaps\n",
    "\n",
    "images[0].save(\n",
    "    'kmeans.gif',\n",
    "    optimize=False,\n",
    "    save_all=True,\n",
    "    append_images=images[1:],\n",
    "    loop=0,\n",
    "    duration=500\n",
    ")\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "76ca05dc3ea24b2e3b98cdb7774adfbb40773424bf5109b477fd793f623715af"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
